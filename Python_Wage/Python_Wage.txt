import pandas as pd
import numpy as np
data=pd.read_csv('C:/Users/Ian/Desktop/Working/Python_Wage/DataWage.txt', header=0,)

female=np.ravel(pd.DataFrame.as_matrix(data[['FEMALE']]))
nonwhite=np.ravel(pd.DataFrame.as_matrix(data[['NONWHITE']]))
union=np.ravel(pd.DataFrame.as_matrix(data[['UNION']]))
educ=np.ravel(pd.DataFrame.as_matrix(data[['EDUC']]))
age=np.ravel(pd.DataFrame.as_matrix(data[['AGE']]))
exper=np.ravel(pd.DataFrame.as_matrix(data[['EXPER']]))
wage=np.ravel(pd.DataFrame.as_matrix(data[['WAGE']]))
lnwage=np.ravel(pd.DataFrame.as_matrix(data[['LNWAGE']]))



#Figure 2.5: Distributions of Wages and Log Wages (in progress)
import numpy as np
import matplotlib.pyplot as plt
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.hist(wage, bins=28)
ax2.hist(lnwage, bins=40)
plt.show()

import scipy as sci
from scipy.stats.kde import gaussian_kde
import numpy as np
import matplotlib.pyplot as plt
from numpy import linspace
temp1 = wage[~np.isnan(wage)]
temp2 = lnwage[~np.isnan(lnwage)]
kwage = gaussian_kde(temp1)
klnwage = gaussian_kde(temp2)
f, (ax1, ax2) = plt.subplots(1, 2)
x = linspace(-50,80,100)
ax1.plot((x,kwage(x)))
#from numpy import linspace
#y = linespace(0,5,100)
#ax2.plot((y,klnwage(y)))
plt.show()



#Figure 3.1: Distributions of Log Wage, Education and Experience
import numpy as np
import matplotlib.pyplot as plt
f, (ax1, ax2, ax3) = plt.subplots(3, 1)
ax1.hist(lnwage, bins=40)
ax2.hist(educ, bins=40)
ax3.hist(exper, bins=25)
plt.show()



#Figure 3.2: (Log Wage, Education) Scatterplot
import numpy as np
import matplotlib.pyplot as plt
plt.plot(educ, lnwage, 'bo')
plt.xlim(0,24)
plt.ylim(0,5)
plt.show()



#Figure 3.3: (Log Wage, Education) Scatterplot with Superimposed Regression Line
import numpy as np
import matplotlib.pyplot as plt
from pylab import * 
m,b = np.polyfit(educ,lnwage,1)
plt.plot(educ, lnwage, 'bo', educ, m*educ+b, 'r-')
plt.xlim(0,24)
plt.ylim(0,5)
plt.show()



#Figure 3.4: Regression Output
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
X = data[['EDUC', 'EXPER', ]]
y = data['LNWAGE']
X = stm.add_constant(X)
est = sm.OLS(y, X).fit()
print(est.summary())

#Figure 3.5: Wage Regression Residual Scatter
z=est.fittedvalues
plt.plot(z, y, 'bo')
plt.xlim(0,5)
plt.ylim(0,5)
plt.show()

#Figure 3.6: Wage Regression Residual Plot
res1=y-z
plt.plot(y, 'r-', z, 'g-', res1, 'b-')
plt.xlim(0, len(y))
plt.show()



#Figure 4.1: Histograms for Wage Covariates
import numpy as np
import matplotlib.pyplot as plt
f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)
ax1.hist(educ, bins=40)
ax2.hist(exper, bins=25)
ax3.hist(nonwhite)
ax4.hist(union)
plt.show()



#Figure 4.2: Wage Regression on Education and Experience
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
X = data[['EDUC', 'EXPER', ]]
y = data['LNWAGE']
X = stm.add_constant(X)
est = sm.OLS(y, X).fit()
print(est.summary())



#Figure 4.3: Wage Regression on Education, Experience and Group Dummies
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
X = data[['EDUC', 'EXPER','FEMALE', 'NONWHITE', 'UNION' ]]
y = data['LNWAGE']
X = stm.add_constant(X)
est2 = sm.OLS(y, X).fit()
print(est2.summary())

#Figure 4.4: Residual Scatter from Wage Regression on Education, Experience and Group Dummies
z=est2.fittedvalues
plt.plot(z, y, 'bo')
plt.xlim(0,5)
plt.ylim(0,5)
plt.show()



#Figure 5.1: Basic Linear Wage Regression
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
X = data[['EDUC', 'EXPER','FEMALE', 'NONWHITE', 'UNION' ]]
y = data['LNWAGE']
X = stm.add_constant(X)
est2 = sm.OLS(y, X).fit()
print(est2.summary())



#Figure 5.2: Quadratic Wage Regression
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
educ2 = educ*educ
exper2 = exper*exper
edu_exp = educ*exper
X = data[['EDUC', 'EXPER','FEMALE', 'UNION', 'NONWHITE' ]]
X.insert(2, 'EDU_EXP', edu_exp)
X.insert(2, 'EXPER2', exper2)
X.insert(2, 'EDUC2', educ2)
Y = data['LNWAGE']
X = stm.add_constant(X)
est3 = sm.OLS(Y, X).fit()
print(est3.summary())



#Figure 5.3: Wage Regression on Education, Experience, Group Dummies, and Interactions
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
fem_uni = female*union
fem_non = female*nonwhite
uni_non = union*nonwhite
X = data[['EDUC', 'EXPER','FEMALE', 'UNION', 'NONWHITE' ]]
X.insert(5, 'UNI_NON', uni_non)
X.insert(5, 'FEM_NON', fem_non)
X.insert(5, 'FEM_UNI', fem_uni)
Y = data['LNWAGE']
X = stm.add_constant(X)
est4 = sm.OLS(Y, X).fit()
print(est4.summary())



#Figure 5.4: Wage Regression with Continuous Non-Linearities and Interactions, and Discrete Interactions
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
fem_uni = female*union
fem_non = female*nonwhite
uni_non = union*nonwhite
X = data[['EDUC', 'EXPER','FEMALE', 'UNION', 'NONWHITE' ]]
X.insert(2, 'EDU_EXP', edu_exp)
X.insert(2, 'EXPER2', exper2)
X.insert(2, 'EDUC2', educ2)
X.insert(8, 'UNI_NON', uni_non)
X.insert(8, 'FEM_NON', fem_non)
X.insert(8, 'FEM_UNI', fem_uni)
Y = data['LNWAGE']
X = stm.add_constant(X)
est5 = sm.OLS(Y, X).fit()
print(est5.summary())



#Repeated throughout chapter 8-------
import numpy as np
import pandas as pd
import statsmodels.formula.api as sm
import statsmodels.api as stm
from sklearn.linear_model import LinearRegression
import scipy, scipy.stats
educ2 = educ*educ
exper2 = exper*exper
edu_exp = educ*exper
X = data[['EDUC', 'EXPER','FEMALE', 'UNION', 'NONWHITE' ]]
X.insert(2, 'EDU_EXP', edu_exp)
X.insert(2, 'EXPER2', exper2)
X.insert(2, 'EDUC2', educ2)
Y = data['LNWAGE']
X = stm.add_constant(X)
est3 = sm.OLS(Y, X).fit()
print(est3.summary())

#Chapter 8: resid^2 vs educ
import matplotlib.pyplot as plt
resid= Y-est3.fittedvalues
resid2= z*z
plt.plot(educ, z2, 'bo')
plt.xlim(0,24)
plt.ylim(0,3.63)
plt.show()